#!/usr/bin/env python3
"""
YOLOv5 API å¹¶å‘æµ‹è¯•è„šæœ¬

ä½¿ç”¨æ–¹æ³•:
    python test_concurrent.py --url http://localhost:8080 --api-key test-api-key-123
    python test_concurrent.py --url http://your-domain.com --api-key your-key --concurrency 50 --requests 200
    python test_concurrent.py --url http://localhost:8080 --api-key test-api-key-123 --image-dir /path/to/images
"""

import argparse
import base64
import json
import time
import statistics
import threading
import queue
import os
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib import request, error
from io import BytesIO
from pathlib import Path

def load_images_from_dir(image_dir: str) -> list:
    """ä»Žæ–‡ä»¶å¤¹åŠ è½½æ‰€æœ‰å›¾ç‰‡å¹¶è½¬ä¸º Base64"""
    supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.webp', '.gif'}
    images = []

    image_path = Path(image_dir)
    if not image_path.exists():
        raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {image_dir}")

    for file in image_path.iterdir():
        if file.suffix.lower() in supported_formats:
            try:
                with open(file, 'rb') as f:
                    image_base64 = base64.b64encode(f.read()).decode('utf-8')
                    images.append({
                        'filename': file.name,
                        'base64': image_base64,
                        'size': len(image_base64)
                    })
            except Exception as e:
                print(f"âš ï¸  è·³è¿‡æ–‡ä»¶ {file.name}: {e}")

    if not images:
        raise ValueError(f"ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶: {image_dir}")

    return images


# ç”Ÿæˆæµ‹è¯•å›¾ç‰‡ï¼ˆç®€å•çš„å½©è‰²å›¾ç‰‡ï¼‰
def generate_test_image(width=640, height=480):
    """ç”Ÿæˆä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡ï¼ˆä¸ä¾èµ– PILï¼‰"""
    try:
        from PIL import Image
        import random

        # åˆ›å»ºéšæœºé¢œè‰²çš„å›¾ç‰‡
        img = Image.new('RGB', (width, height),
                       (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)))

        buffer = BytesIO()
        img.save(buffer, format='JPEG', quality=85)
        buffer.seek(0)
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    except ImportError:
        # å¦‚æžœæ²¡æœ‰ PILï¼Œä½¿ç”¨é¢„è®¾çš„å°å›¾ç‰‡
        # è¿™æ˜¯ä¸€ä¸ª 1x1 çº¢è‰²åƒç´ çš„ JPEG
        minimal_jpeg = bytes([
            0xFF, 0xD8, 0xFF, 0xE0, 0x00, 0x10, 0x4A, 0x46, 0x49, 0x46, 0x00, 0x01,
            0x01, 0x00, 0x00, 0x01, 0x00, 0x01, 0x00, 0x00, 0xFF, 0xDB, 0x00, 0x43,
            0x00, 0x08, 0x06, 0x06, 0x07, 0x06, 0x05, 0x08, 0x07, 0x07, 0x07, 0x09,
            0x09, 0x08, 0x0A, 0x0C, 0x14, 0x0D, 0x0C, 0x0B, 0x0B, 0x0C, 0x19, 0x12,
            0x13, 0x0F, 0x14, 0x1D, 0x1A, 0x1F, 0x1E, 0x1D, 0x1A, 0x1C, 0x1C, 0x20,
            0x24, 0x2E, 0x27, 0x20, 0x22, 0x2C, 0x23, 0x1C, 0x1C, 0x28, 0x37, 0x29,
            0x2C, 0x30, 0x31, 0x34, 0x34, 0x34, 0x1F, 0x27, 0x39, 0x3D, 0x38, 0x32,
            0x3C, 0x2E, 0x33, 0x34, 0x32, 0xFF, 0xC0, 0x00, 0x0B, 0x08, 0x00, 0x01,
            0x00, 0x01, 0x01, 0x01, 0x11, 0x00, 0xFF, 0xC4, 0x00, 0x1F, 0x00, 0x00,
            0x01, 0x05, 0x01, 0x01, 0x01, 0x01, 0x01, 0x01, 0x00, 0x00, 0x00, 0x00,
            0x00, 0x00, 0x00, 0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08,
            0x09, 0x0A, 0x0B, 0xFF, 0xC4, 0x00, 0xB5, 0x10, 0x00, 0x02, 0x01, 0x03,
            0x03, 0x02, 0x04, 0x03, 0x05, 0x05, 0x04, 0x04, 0x00, 0x00, 0x01, 0x7D,
            0x01, 0x02, 0x03, 0x00, 0x04, 0x11, 0x05, 0x12, 0x21, 0x31, 0x41, 0x06,
            0x13, 0x51, 0x61, 0x07, 0x22, 0x71, 0x14, 0x32, 0x81, 0x91, 0xA1, 0x08,
            0x23, 0x42, 0xB1, 0xC1, 0x15, 0x52, 0xD1, 0xF0, 0x24, 0x33, 0x62, 0x72,
            0x82, 0x09, 0x0A, 0x16, 0x17, 0x18, 0x19, 0x1A, 0x25, 0x26, 0x27, 0x28,
            0x29, 0x2A, 0x34, 0x35, 0x36, 0x37, 0x38, 0x39, 0x3A, 0x43, 0x44, 0x45,
            0x46, 0x47, 0x48, 0x49, 0x4A, 0x53, 0x54, 0x55, 0x56, 0x57, 0x58, 0x59,
            0x5A, 0x63, 0x64, 0x65, 0x66, 0x67, 0x68, 0x69, 0x6A, 0x73, 0x74, 0x75,
            0x76, 0x77, 0x78, 0x79, 0x7A, 0x83, 0x84, 0x85, 0x86, 0x87, 0x88, 0x89,
            0x8A, 0x92, 0x93, 0x94, 0x95, 0x96, 0x97, 0x98, 0x99, 0x9A, 0xA2, 0xA3,
            0xA4, 0xA5, 0xA6, 0xA7, 0xA8, 0xA9, 0xAA, 0xB2, 0xB3, 0xB4, 0xB5, 0xB6,
            0xB7, 0xB8, 0xB9, 0xBA, 0xC2, 0xC3, 0xC4, 0xC5, 0xC6, 0xC7, 0xC8, 0xC9,
            0xCA, 0xD2, 0xD3, 0xD4, 0xD5, 0xD6, 0xD7, 0xD8, 0xD9, 0xDA, 0xE1, 0xE2,
            0xE3, 0xE4, 0xE5, 0xE6, 0xE7, 0xE8, 0xE9, 0xEA, 0xF1, 0xF2, 0xF3, 0xF4,
            0xF5, 0xF6, 0xF7, 0xF8, 0xF9, 0xFA, 0xFF, 0xDA, 0x00, 0x08, 0x01, 0x01,
            0x00, 0x00, 0x3F, 0x00, 0xFB, 0xD5, 0xDB, 0x20, 0xA8, 0xF1, 0x45, 0x00,
            0xFF, 0xD9
        ])
        return base64.b64encode(minimal_jpeg).decode('utf-8')


class APITester:
    """API å¹¶å‘æµ‹è¯•å™¨"""

    def __init__(self, base_url: str, api_key: str, timeout: int = 30):
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.timeout = timeout
        self.results = queue.Queue()

    def single_request(self, image_data: dict, request_id: int) -> dict:
        """å‘é€å•ä¸ªæ£€æµ‹è¯·æ±‚"""
        url = f"{self.base_url}/api/aapi"

        # æ”¯æŒä¼ å…¥ dictï¼ˆåŒ…å« filenameï¼‰æˆ– strï¼ˆçº¯ base64ï¼‰
        if isinstance(image_data, dict):
            image_base64 = image_data['base64']
            filename = image_data.get('filename', 'unknown')
        else:
            image_base64 = image_data
            filename = 'generated'

        headers = {
            'Content-Type': 'application/json',
            'X-API-Key': self.api_key
        }

        data = json.dumps({'img': image_base64}).encode('utf-8')

        start_time = time.time()
        result = {
            'request_id': request_id,
            'filename': filename,
            'success': False,
            'status_code': None,
            'response_time': 0,
            'detections': 0,
            'detection_details': [],
            'error': None
        }

        try:
            req = request.Request(url, data=data, headers=headers, method='POST')
            with request.urlopen(req, timeout=self.timeout) as response:
                result['status_code'] = response.status
                response_data = json.loads(response.read().decode('utf-8'))
                result['success'] = True
                result['detections'] = len(response_data.get('detections', []))
                result['detection_details'] = response_data.get('detections', [])
                result['process_time'] = response_data.get('process_time', 0)

        except error.HTTPError as e:
            result['status_code'] = e.code
            result['error'] = f"HTTP {e.code}: {e.reason}"
        except error.URLError as e:
            result['error'] = f"URL Error: {e.reason}"
        except Exception as e:
            result['error'] = str(e)

        result['response_time'] = time.time() - start_time
        return result

    def run_concurrent_test(self, concurrency: int, total_requests: int, images: list) -> dict:
        """è¿è¡Œå¹¶å‘æµ‹è¯•"""
        print(f"\n{'='*60}")
        print(f"å¼€å§‹å¹¶å‘æµ‹è¯•")
        print(f"{'='*60}")
        print(f"ç›®æ ‡åœ°å€: {self.base_url}")
        print(f"å¹¶å‘æ•°: {concurrency}")
        print(f"æ€»è¯·æ±‚æ•°: {total_requests}")
        print(f"å›¾ç‰‡æ•°é‡: {len(images)}")
        print(f"{'='*60}\n")

        results = []
        start_time = time.time()
        completed = 0

        with ThreadPoolExecutor(max_workers=concurrency) as executor:
            futures = {}
            for i in range(total_requests):
                # å¾ªçŽ¯ä½¿ç”¨å›¾ç‰‡åˆ—è¡¨
                image_data = images[i % len(images)]
                futures[executor.submit(self.single_request, image_data, i)] = i

            for future in as_completed(futures):
                result = future.result()
                results.append(result)
                completed += 1

                # è¿›åº¦æ˜¾ç¤º
                if completed % 10 == 0 or completed == total_requests:
                    success_count = sum(1 for r in results if r['success'])
                    print(f"è¿›åº¦: {completed}/{total_requests} | æˆåŠŸ: {success_count} | å¤±è´¥: {completed - success_count}")

        total_time = time.time() - start_time

        # ç»Ÿè®¡åˆ†æž
        return self.analyze_results(results, total_time, concurrency)

    def analyze_results(self, results: list, total_time: float, concurrency: int) -> dict:
        """åˆ†æžæµ‹è¯•ç»“æžœ"""
        successful = [r for r in results if r['success']]
        failed = [r for r in results if not r['success']]

        response_times = [r['response_time'] for r in successful]
        process_times = [r.get('process_time', 0) for r in successful if r.get('process_time')]

        stats = {
            'total_requests': len(results),
            'successful': len(successful),
            'failed': len(failed),
            'success_rate': len(successful) / len(results) * 100 if results else 0,
            'total_time': total_time,
            'qps': len(results) / total_time if total_time > 0 else 0,
            'concurrency': concurrency,
        }

        if response_times:
            stats['response_time'] = {
                'min': min(response_times),
                'max': max(response_times),
                'avg': statistics.mean(response_times),
                'median': statistics.median(response_times),
                'p95': sorted(response_times)[int(len(response_times) * 0.95)] if len(response_times) >= 20 else max(response_times),
                'p99': sorted(response_times)[int(len(response_times) * 0.99)] if len(response_times) >= 100 else max(response_times),
            }

        if process_times:
            stats['process_time'] = {
                'min': min(process_times),
                'max': max(process_times),
                'avg': statistics.mean(process_times),
            }

        # é”™è¯¯ç»Ÿè®¡
        if failed:
            error_counts = {}
            for r in failed:
                err = r.get('error', 'Unknown')
                error_counts[err] = error_counts.get(err, 0) + 1
            stats['errors'] = error_counts

        return stats

    def print_report(self, stats: dict):
        """æ‰“å°æµ‹è¯•æŠ¥å‘Š"""
        print(f"\n{'='*60}")
        print("æµ‹è¯•ç»“æžœæŠ¥å‘Š")
        print(f"{'='*60}")

        print(f"\nðŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"   æ€»è¯·æ±‚æ•°:     {stats['total_requests']}")
        print(f"   æˆåŠŸè¯·æ±‚:     {stats['successful']}")
        print(f"   å¤±è´¥è¯·æ±‚:     {stats['failed']}")
        print(f"   æˆåŠŸçŽ‡:       {stats['success_rate']:.2f}%")
        print(f"   æ€»è€—æ—¶:       {stats['total_time']:.2f}s")
        print(f"   å¹¶å‘æ•°:       {stats['concurrency']}")
        print(f"   QPS:          {stats['qps']:.2f}")

        if 'response_time' in stats:
            rt = stats['response_time']
            print(f"\nâ±ï¸  å“åº”æ—¶é—´ (ç§’):")
            print(f"   æœ€å°:         {rt['min']:.3f}s")
            print(f"   æœ€å¤§:         {rt['max']:.3f}s")
            print(f"   å¹³å‡:         {rt['avg']:.3f}s")
            print(f"   ä¸­ä½æ•°:       {rt['median']:.3f}s")
            print(f"   P95:          {rt['p95']:.3f}s")
            print(f"   P99:          {rt['p99']:.3f}s")

        if 'process_time' in stats:
            pt = stats['process_time']
            print(f"\nðŸ” æ¨¡åž‹æŽ¨ç†æ—¶é—´ (ç§’):")
            print(f"   æœ€å°:         {pt['min']:.3f}s")
            print(f"   æœ€å¤§:         {pt['max']:.3f}s")
            print(f"   å¹³å‡:         {pt['avg']:.3f}s")

        if 'errors' in stats:
            print(f"\nâŒ é”™è¯¯ç»Ÿè®¡:")
            for err, count in stats['errors'].items():
                print(f"   {err}: {count}")

        print(f"\n{'='*60}")

        # æ€§èƒ½è¯„ä¼°
        print("\nðŸ“ˆ æ€§èƒ½è¯„ä¼°:")
        qps = stats['qps']
        if qps >= 50:
            print(f"   âœ… QPS {qps:.1f} - æ€§èƒ½ä¼˜ç§€")
        elif qps >= 20:
            print(f"   âš ï¸  QPS {qps:.1f} - æ€§èƒ½ä¸€èˆ¬ï¼Œå»ºè®®å¢žåŠ  Worker æˆ–ä¼˜åŒ–æ¨¡åž‹")
        else:
            print(f"   âŒ QPS {qps:.1f} - æ€§èƒ½è¾ƒä½Žï¼Œå»ºè®®æ£€æŸ¥æœåŠ¡å™¨é…ç½®")

        if stats['success_rate'] >= 99:
            print(f"   âœ… æˆåŠŸçŽ‡ {stats['success_rate']:.1f}% - ç¨³å®šæ€§ä¼˜ç§€")
        elif stats['success_rate'] >= 95:
            print(f"   âš ï¸  æˆåŠŸçŽ‡ {stats['success_rate']:.1f}% - å­˜åœ¨å°‘é‡å¤±è´¥")
        else:
            print(f"   âŒ æˆåŠŸçŽ‡ {stats['success_rate']:.1f}% - éœ€è¦æŽ’æŸ¥é—®é¢˜")


def health_check(base_url: str) -> bool:
    """å¥åº·æ£€æŸ¥"""
    url = f"{base_url.rstrip('/')}/api/health"
    try:
        req = request.Request(url)
        with request.urlopen(req, timeout=5) as response:
            return response.status == 200
    except:
        return False


def main():
    parser = argparse.ArgumentParser(description='YOLOv5 API å¹¶å‘æµ‹è¯•å·¥å…·')
    parser.add_argument('--url', type=str, default='http://localhost:8080',
                       help='API æœåŠ¡åœ°å€ (é»˜è®¤: http://localhost:8080)')
    parser.add_argument('--api-key', type=str, default='test-api-key-123',
                       help='API Key (é»˜è®¤: test-api-key-123)')
    parser.add_argument('--concurrency', '-c', type=int, default=10,
                       help='å¹¶å‘æ•° (é»˜è®¤: 10)')
    parser.add_argument('--requests', '-n', type=int, default=100,
                       help='æ€»è¯·æ±‚æ•° (é»˜è®¤: 100)')
    parser.add_argument('--timeout', '-t', type=int, default=30,
                       help='è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 30)')
    parser.add_argument('--image', type=str, default=None,
                       help='æµ‹è¯•å›¾ç‰‡è·¯å¾„ (å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ç”Ÿæˆçš„æµ‹è¯•å›¾ç‰‡)')
    parser.add_argument('--image-dir', type=str, default=None,
                       help='æµ‹è¯•å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ (å¯é€‰ï¼Œä¼šä½¿ç”¨æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰å›¾ç‰‡)')

    args = parser.parse_args()

    print("ðŸš€ YOLOv5 API å¹¶å‘æµ‹è¯•å·¥å…·")
    print(f"{'='*60}")

    # å¥åº·æ£€æŸ¥
    print(f"æ£€æŸ¥æœåŠ¡çŠ¶æ€: {args.url}")
    if not health_check(args.url):
        print("âŒ æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯åŠ¨")
        return 1
    print("âœ… æœåŠ¡æ­£å¸¸\n")

    # å‡†å¤‡æµ‹è¯•å›¾ç‰‡
    images = []

    if args.image_dir:
        # ä»Žæ–‡ä»¶å¤¹åŠ è½½å›¾ç‰‡
        print(f"ðŸ“ ä»Žæ–‡ä»¶å¤¹åŠ è½½å›¾ç‰‡: {args.image_dir}")
        images = load_images_from_dir(args.image_dir)
        print(f"   æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡:")
        for img in images[:5]:  # åªæ˜¾ç¤ºå‰5å¼ 
            print(f"   - {img['filename']} ({img['size']} bytes)")
        if len(images) > 5:
            print(f"   ... è¿˜æœ‰ {len(images) - 5} å¼ å›¾ç‰‡")
    elif args.image:
        # åŠ è½½å•å¼ å›¾ç‰‡
        print(f"åŠ è½½æµ‹è¯•å›¾ç‰‡: {args.image}")
        with open(args.image, 'rb') as f:
            image_base64 = base64.b64encode(f.read()).decode('utf-8')
        images = [{'filename': os.path.basename(args.image), 'base64': image_base64, 'size': len(image_base64)}]
    else:
        # ç”Ÿæˆæµ‹è¯•å›¾ç‰‡
        print("ç”Ÿæˆæµ‹è¯•å›¾ç‰‡...")
        image_base64 = generate_test_image()
        images = [{'filename': 'generated.jpg', 'base64': image_base64, 'size': len(image_base64)}]

    print(f"\næ€»å›¾ç‰‡æ•°: {len(images)}")
    total_size = sum(img['size'] for img in images)
    print(f"æ€»å¤§å°: {total_size / 1024:.1f} KB (Base64)\n")

    # è¿è¡Œæµ‹è¯•
    tester = APITester(args.url, args.api_key, args.timeout)
    stats = tester.run_concurrent_test(args.concurrency, args.requests, images)

    # æ‰“å°æŠ¥å‘Š
    tester.print_report(stats)

    return 0 if stats['success_rate'] >= 95 else 1


if __name__ == '__main__':
    exit(main())
